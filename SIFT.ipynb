{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlXoj5_LX8xs"
   },
   "source": [
    "# Shiraz University Of Technology\n",
    "## Javid Norouzi\n",
    "### SIFT (Scale Invariant Feature Transform)\n",
    "### Based on procedure in\n",
    "### Anatomy Of the SIFT Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6edOa7nX8xt"
   },
   "source": [
    "<pre></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nd15d0ztX8xu"
   },
   "source": [
    "<pre></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ri_s12UX8xv"
   },
   "source": [
    "#### Impoting Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGhtv26NX8xw",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PrwxTahX8x0"
   },
   "source": [
    "#### Class to hold information about each interest point\n",
    "x,y : Refined Location <br>\n",
    "m,n : Discrete Location <br>\n",
    "octave : Octave in which key point is detected in <br>\n",
    "scale : Scale in which key point is detected in<br>\n",
    "w : DoG responce in refined location<br>\n",
    "orientation : Key Point Orientation<br>\n",
    "descriptor : Key Point Descriptor<br>\n",
    "pt() : Returns refined location as a Tuple<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWwU7mpnX8x1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class keyPoint:\n",
    "    def __init__(self, octave=None, scale=None, m=None, n=None, x=None, y=None, sigma=None, w=None, ori=None, desc=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.octave = octave\n",
    "        self.scale = scale\n",
    "        self.sigma = sigma\n",
    "        self.w = w\n",
    "        self.orientation = ori\n",
    "        self.descriptor = desc\n",
    "\n",
    "    def pt(self):\n",
    "        return int(self.x), int(self.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnG8DAlZX8x5"
   },
   "source": [
    "## Some Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3eFDGMDpX8x6"
   },
   "source": [
    "#### 2D Hessian in surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSKgQDmvX8x7",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def hessian2d(surface):\n",
    "    h11 = surface[2, 1] + surface[0, 1] - 2 * surface[1, 1]\n",
    "    h22 = surface[1, 2] + surface[1, 0] - 2 * surface[1, 1]\n",
    "    h12 = (surface[2, 2] - surface[2, 0] - surface[0, 2] + surface[0, 0]) / 4\n",
    "    return np.array([[h11, h12],\n",
    "                     [h12, h22]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1nqrKKJX8x_"
   },
   "source": [
    "####  3D Gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mi74V_r_X8yA",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def gradientAtCubeCenter(cube):\n",
    "    ds = 0.5 * (cube[2, 1, 1] - cube[0, 1, 1])\n",
    "    dm = 0.5 * (cube[1, 2, 1] - cube[1, 0, 1])\n",
    "    dn = 0.5 * (cube[1, 1, 2] - cube[1, 1, 0])\n",
    "\n",
    "    return np.array([ds, dm, dn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_pi-KwjX8yD"
   },
   "source": [
    "#### 3D Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K31lFSbgX8yE",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def hessianAtCubeCenter(cube):\n",
    "    center_point = cube[1, 1, 1]\n",
    "    h11 = cube[2, 1, 1] - 2 * center_point + cube[0, 1, 1]\n",
    "    h22 = cube[1, 2, 1] - 2 * center_point + cube[1, 0, 1]\n",
    "    h33 = cube[1, 1, 2] - 2 * center_point + cube[1, 1, 0]\n",
    "    h12 = 0.25 * (cube[2, 2, 1] - cube[2, 0, 1] - cube[0, 2, 1] + cube[0, 0, 1])\n",
    "    h13 = 0.25 * (cube[2, 1, 2] - cube[2, 1, 0] - cube[0, 1, 2] + cube[0, 1, 0])\n",
    "    h23 = 0.25 * (cube[1, 2, 2] - cube[1, 2, 0] - cube[1, 0, 2] + cube[1, 0, 0])\n",
    "    return np.array([[h11, h12, h13],\n",
    "                     [h12, h22, h23],\n",
    "                     [h13, h23, h33]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "upR9eGBeX8yI"
   },
   "source": [
    "#### Displays a 4D Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-qMQOVIX8yJ",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def showSpace(space, color_map='gray'):\n",
    "    n_octave, n_image_per_octave = space.shape\n",
    "    figure, ax = plt.subplots(n_octave, n_image_per_octave, figsize=(24, 20))\n",
    "\n",
    "    for octave in range(n_octave):\n",
    "        for image_index in range(n_image_per_octave):\n",
    "            pos = ax[octave, image_index].imshow(space[octave, image_index], cmap=color_map)\n",
    "            figure.colorbar(pos, ax=ax[octave, image_index])\n",
    "    \n",
    "    figure.canvas.draw()\n",
    "#     plt.show()\n",
    "    return  np.array(figure.canvas.buffer_rgba())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZyTzAYeRX8yN"
   },
   "source": [
    "#### Smoothes a 1D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuMWxWZJX8yN",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def smoothHist(histogram):\n",
    "    h = np.zeros_like(histogram)\n",
    "    h_size = len(histogram)\n",
    "    for iteration in range(6):\n",
    "        for i in range(len(histogram)):\n",
    "            h_p = histogram[(i - 1) % h_size]\n",
    "            h_c = histogram[i]\n",
    "            h_n = histogram[(i + 1) % h_size]\n",
    "            h[i] = (h_p + h_n + h_c) / 3\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVRf2pZ_X8yR"
   },
   "source": [
    "#### Draw Key Points on given image based on key points list\n",
    "#### Each Circle's radius aquals to the keypoint's sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DR-v4IYX8yS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def drawKeyPoints(img, key_points, title=\"\"):\n",
    "    img_cp = img.copy() * 255\n",
    "    for point in key_points:\n",
    "        x, y = point.pt()\n",
    "        pt1 = (y, x)\n",
    "        r = int(point.sigma)\n",
    "        ori = point.orientation\n",
    "        cv2.circle(img_cp, pt1, r, (255, 255, 255), 1)\n",
    "        if r > 2:\n",
    "            a = cos(ori) * r\n",
    "            b = sin(ori) * r\n",
    "            pt2 = ( pt1[0] + round(b),pt1[1] + round(a))\n",
    "            cv2.line(img_cp, pt1, pt2, (255, 255, 255))\n",
    "\n",
    "#     plt.figure(figsize=(24, 20)).add_subplot(title=title).imshow(img_cp)\n",
    "#     plt.show()\n",
    "    return img_cp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3U17oUMX8yZ"
   },
   "source": [
    "#### Exactly like the previous function but within a  Rotated Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-qzBrcUX8ya",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def drawRotRect(img, key_points, title=\"\"):\n",
    "    img_cp = img.copy() * 255\n",
    "    img_height, img_width = img.shape\n",
    "    for point in key_points:\n",
    "        cy, cx = point.pt()\n",
    "        ori = point.orientation\n",
    "        r_rect = int(point.sigma * sqrt(2))\n",
    "\n",
    "        pt1 = (cx + int(cos(ori + pi / 4) * r_rect), cy + int(sin(ori + pi / 4) * r_rect))\n",
    "        pt2 = (cx + int(cos(ori + 3 * pi / 4) * r_rect), cy + int(sin(ori + 3 * pi / 4) * r_rect))\n",
    "        pt3 = (cx + int(cos(ori + 5 * pi / 4) * r_rect), cy + int(sin(ori + 5 * pi / 4) * r_rect))\n",
    "        pt4 = (cx + int(cos(ori + 7 * pi / 4) * r_rect), cy + int(sin(ori + 7 * pi / 4) * r_rect))\n",
    "        cv2.line(img_cp, pt1, pt2, (255, 255, 255))\n",
    "        cv2.line(img_cp, pt2, pt3, (255, 255, 255))\n",
    "        cv2.line(img_cp, pt3, pt4, (255, 255, 255))\n",
    "        cv2.line(img_cp, pt1, pt4, (255, 255, 255))\n",
    "        cv2.line(img_cp, (cx, cy), (cx + int(cos(ori) * r_rect), cy + int(sin(ori) * r_rect)), (255, 255, 255))\n",
    "        \n",
    "    return img_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzoMgVLYX8ye"
   },
   "source": [
    "#### Constructs a 2D numpy array consisting total bluring for each image in gaussian Space <br>\n",
    "InterPixel Distance is assumed distance between image pixels in the input image unlike what is assumed in the original algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gm77fZeX8yf",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def generateBlurringMatrix2(n_octave=5, n_scale_per_octave=3, sigma_min=.8, inter_pixel_distance=1):\n",
    "    k = 2 ** (1 / n_scale_per_octave)\n",
    "    iteration_per_octave = 3 + n_scale_per_octave\n",
    "    blurring_matrix = np.zeros((n_octave, iteration_per_octave))\n",
    "    for octave in range(n_octave):\n",
    "        iteration_sigma_min = 2 ** octave * sigma_min / inter_pixel_distance\n",
    "        blurring_matrix[octave, 0] = iteration_sigma_min\n",
    "        for iteration in range(1, iteration_per_octave):\n",
    "            total_blur = k ** iteration * iteration_sigma_min\n",
    "            blurring_matrix[octave, iteration] = total_blur\n",
    "\n",
    "    return blurring_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "4EPuWFlcX8yi",
    "outputId": "b02b3022-2793-4c5f-ca73-5c31c640172b",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# As an example we have the following\n",
    "generateBlurringMatrix2(n_scale_per_octave=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5s1Tp8rX8yn"
   },
   "source": [
    "## SIFT Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7XxrfR2X8yo"
   },
   "source": [
    "### Generate Digital Guassian Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPELwDXVX8yp",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def generateDigitalGaussianScaleSpace(input_image, n_octave, n_sample_per_octave, sigma_min, inter_pixel_distance, sigma_in):\n",
    "    delta_min = inter_pixel_distance / 2\n",
    "    scale_factor = 1 / delta_min\n",
    "    interpolated_img = cv2.resize(input_image, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)\n",
    "    blur_to_apply =  sqrt(sigma_min ** 2 - sigma_in ** 2) / delta_min\n",
    "    img_per_octave = n_sample_per_octave + 3\n",
    "    gaussian_scale_space = np.zeros(shape=(n_octave, img_per_octave), dtype=np.ndarray)\n",
    "    gaussian_scale_space[0, 0] = cv2.GaussianBlur(interpolated_img, (0, 0), blur_to_apply)\n",
    "\n",
    "    for s in range(1, img_per_octave):\n",
    "        blur_to_apply = sigma_min / delta_min * sqrt(2 ** (2 * s / n_sample_per_octave) - 2 ** (2 * (s - 1) / n_sample_per_octave))\n",
    "        gaussian_scale_space[0, s] = cv2.GaussianBlur(gaussian_scale_space[0, s - 1], (0, 0), sigmaX=blur_to_apply)\n",
    "    for o in range(1, n_octave):\n",
    "        gaussian_scale_space[o, 0] = cv2.resize(gaussian_scale_space[o - 1, n_sample_per_octave], (0, 0), fx=.5, fy=.5, interpolation=cv2.INTER_LINEAR)\n",
    "        for s in range(1, img_per_octave):\n",
    "            blur_to_apply = sigma_min / delta_min * sqrt(2 ** (2 * s / n_sample_per_octave) - 2 ** (2 * (s - 1) / n_sample_per_octave))\n",
    "            gaussian_scale_space[o, s] = cv2.GaussianBlur(gaussian_scale_space[o, s - 1], (0, 0), blur_to_apply)\n",
    "\n",
    "    return gaussian_scale_space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rGN2AZJX8ys"
   },
   "source": [
    "#### Generates the DoG Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UK76aDWdX8yt",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def generateDoG(scale_space):\n",
    "    octave_num, iteration_num = scale_space.shape\n",
    "    DoG = np.zeros_like(scale_space)\n",
    "    for i in range(1, iteration_num):\n",
    "        DoG[:, i - 1] = scale_space[:, i] - scale_space[:, i - 1]\n",
    "    return DoG[:, :-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nU46vMMVX8yx"
   },
   "source": [
    "#### Detects the extremums in the DoG Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1lNuOnOX8yy",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def detectExtremums(difference_of_gaussian, contrast_dog, sigma_min, inter_pixel_distance):\n",
    "    positions = []\n",
    "    candidate_key_points = []\n",
    "    n_octave, n_img_per_octave = difference_of_gaussian.shape\n",
    "    n_sample_per_octave = n_img_per_octave - 3\n",
    "    total_blurring_map = generateBlurringMatrix2(n_octave=n_octave, n_scale_per_octave=n_sample_per_octave, sigma_min=sigma_min, inter_pixel_distance=inter_pixel_distance)\n",
    "    total_blurring_map = np.array(total_blurring_map)\n",
    "    for octave in range(n_octave):\n",
    "        img_height, img_width = difference_of_gaussian[octave, 0].shape\n",
    "        for img_index in range(1, n_img_per_octave - 1):\n",
    "            # fix\n",
    "            three_successive_img = np.stack(difference_of_gaussian[octave, img_index - 1:img_index + 2])\n",
    "            for m in range(1, img_height - 1):\n",
    "                for n in range(1, img_width - 1):\n",
    "                    cube = three_successive_img[:, m - 1:m + 2, n - 1:n + 2]\n",
    "                    # pt = cube[1, 1, 1]\n",
    "                    # cube = np.delete(cube, 13)\n",
    "                    # if pt >= cube.max() or pt <= cube.min():\n",
    "                    # if np.argmax(np.abs(cube)) == 13:\n",
    "                    if (np.argmax(cube) == 13 or np.argmin(cube) == 13) and abs(cube[1, 1, 1]) > .8 * contrast_dog:\n",
    "                        x = inter_pixel_distance * 2 ** (octave - 1) * m\n",
    "                        y = inter_pixel_distance * 2 ** (octave - 1) * n\n",
    "                        candidate_key_points.append(keyPoint(m=m, n=n, x=x, y=y, octave=octave, scale=img_index, ori=0, sigma=total_blurring_map[octave, img_index]))\n",
    "                        positions.append((m + 1, n + 1))\n",
    "    return candidate_key_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfnN3heIX8y1"
   },
   "source": [
    "#### Calculates Gradient of Gaussian Scale Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngSdbhuwX8y1",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def space_gradient(space):\n",
    "    n_octave, n_image_per_octave = space.shape\n",
    "    gradient_m = np.zeros_like(space, dtype=np.ndarray)\n",
    "    gradient_n = np.zeros_like(space, dtype=np.ndarray)\n",
    "\n",
    "    for octave in range(n_octave):\n",
    "        for img_index in range(n_image_per_octave):\n",
    "            gradient_m[octave, img_index] = cv2.Sobel(space[octave, img_index], cv2.CV_64F, 0, 1, 3)\n",
    "            gradient_n[octave, img_index] = cv2.Sobel(space[octave, img_index], cv2.CV_64F, 1, 0, 3)\n",
    "    return gradient_m, gradient_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4LK0P1NX8y5"
   },
   "source": [
    "### Discarding low contrast points in DoG space (A conservative test to prevent unneccacery calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hf-s6-QUX8y5",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def discardLowContrastPointsConservative(key_points, difference_of_gaussian, contrast_dog):\n",
    "    candidate_key_points = []\n",
    "    for point in key_points:\n",
    "        o = point.octave\n",
    "        s = point.scale\n",
    "        m = point.m\n",
    "        n = point.n\n",
    "        if abs(difference_of_gaussian[o, s][m, n]) > .8 * contrast_dog:\n",
    "            candidate_key_points.append(point)\n",
    "\n",
    "    return candidate_key_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQJRYJsHX8y8"
   },
   "source": [
    "### Discarding low contrast points after refining position and response in DoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HXMOZqqX8y9",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def discardLowContrastPoints(keyPoints, contrast):\n",
    "    final_list = []\n",
    "    for point in keyPoints:\n",
    "        if abs(point.w) > contrast:\n",
    "            final_list.append(point)\n",
    "    return final_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DktJAIhIX8zA"
   },
   "source": [
    "### Refining KeyPoints positions by quadratic interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UFdG2FDX8zB",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def refinePositions(candidate_key_points, difference_of_gaussian_space, n_attempts, inter_pixel_distance, sigma_min):\n",
    "    n_octave, n_img_per_octave = difference_of_gaussian_space.shape\n",
    "    n_sample_per_octave = n_img_per_octave - 2\n",
    "    final_key_point_list = []\n",
    "    for point in candidate_key_points:\n",
    "        o = point.octave\n",
    "        s = point.scale\n",
    "        m = point.m\n",
    "        n = point.n\n",
    "        outside_bound = False\n",
    "        img_height, img_width = difference_of_gaussian_space[o, 0].shape\n",
    "        for attempt in range(n_attempts):\n",
    "            if not 0 < m < img_height - 1 or not 0 < n < img_width - 1 or not 0 < s < n_img_per_octave - 1:\n",
    "                outside_bound = True\n",
    "                break\n",
    "            offset, w = quadraticInterPolate(difference_of_gaussian_space=difference_of_gaussian_space, point=(o, s, m, n))\n",
    "            sigma = 2 ** o * sigma_min * 2 ** ((offset[0] + s) / n_sample_per_octave)\n",
    "            x = inter_pixel_distance * 2 ** (o - 1) * (offset[1] + m)\n",
    "            y = inter_pixel_distance * 2 ** (o - 1) * (offset[2] + n)\n",
    "            s += np.round(offset).astype(np.int)[0]\n",
    "            m += np.round(offset).astype(np.int)[1]\n",
    "            n += np.round(offset).astype(np.int)[2]\n",
    "            if np.all(offset < .5):\n",
    "                break\n",
    "\n",
    "        if outside_bound:\n",
    "            continue\n",
    "\n",
    "        if np.any(np.abs(offset) > 1):\n",
    "            continue\n",
    "\n",
    "        point.x = x\n",
    "        point.y = y\n",
    "        point.w = w\n",
    "        point.sigma = sigma\n",
    "\n",
    "        final_key_point_list.append(point)\n",
    "\n",
    "    return final_key_point_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpP0BYKlX8zE"
   },
   "source": [
    "### Quadratic InterPolation at a single point in DoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBm0AKRiX8zF",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def quadraticInterPolate(difference_of_gaussian_space, point):\n",
    "    o, s, m, n = point\n",
    "    three_successive_img = np.stack(difference_of_gaussian_space[o, s - 1:s + 2])\n",
    "    cube = three_successive_img[:, m - 1:m + 2, n - 1:n + 2]\n",
    "    hessian = hessianAtCubeCenter(cube)\n",
    "    gradient = gradientAtCubeCenter(cube)\n",
    "    offset = -np.linalg.lstsq(hessian, gradient, rcond=None)[0]\n",
    "    # offset = -np.linalg.inv(hessian) @ gradient\n",
    "    w = difference_of_gaussian_space[o, s][m, n] + .5 * gradient.T @ offset\n",
    "    return offset, w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmoHXbWYX8zK"
   },
   "source": [
    "### Discarding edge response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nPwa5cdX8zK",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def discardEdgeResponse(key_point_list, difference_of_gaussian_space, r_edge, n_octave, n_sample_per_octave, sigma_min, inter_pixel_distance):\n",
    "    total_blurring_map = generateBlurringMatrix2(n_octave=n_octave, n_scale_per_octave=n_sample_per_octave, sigma_min=sigma_min, inter_pixel_distance=inter_pixel_distance)\n",
    "    total_blurring_map = np.array(total_blurring_map)\n",
    "    final_list = []\n",
    "    for point in key_point_list:\n",
    "        o = point.octave\n",
    "        m = point.m\n",
    "        n = point.n\n",
    "        sigma_dist = np.abs(total_blurring_map[point.octave] - point.sigma)\n",
    "        closest_scale = np.argmin(sigma_dist)\n",
    "        current_plane = np.stack(difference_of_gaussian_space[o, closest_scale])\n",
    "        surface = current_plane[m - 1:m + 2, n - 1:n + 2]\n",
    "        hessian = hessian2d(surface)\n",
    "        hessian_trace = np.trace(hessian)\n",
    "        hessian_det = np.linalg.det(hessian)\n",
    "        edgeness = hessian_trace ** 2 / hessian_det\n",
    "        if edgeness < (r_edge + 1) ** 2 / r_edge:\n",
    "            final_list.append(point)\n",
    "    return final_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5PYjCDZX8zO"
   },
   "source": [
    "### Detecting each keypoint's orientations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frLQHaB4X8zO",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def computeKeyPointOrientation(key_point_list, gradient_of_scale_space, l_ori, n_bins, t_secondary, sigma_min, n_octave, n_sample_per_octave, inter_pixel_distance):\n",
    "    total_blurring_map = generateBlurringMatrix2(n_octave=n_octave, n_scale_per_octave=n_sample_per_octave, sigma_min=sigma_min, inter_pixel_distance=inter_pixel_distance)\n",
    "    total_blurring_map = total_blurring_map[:, 1:-2]\n",
    "    gradient_m = gradient_of_scale_space[0]\n",
    "    gradient_n = gradient_of_scale_space[1]\n",
    "    gradient_m = gradient_m[:, 1:-2]\n",
    "    gradient_n = gradient_n[:, 1:-2]\n",
    "    plane_height, plane_width = gradient_m[1, 0].shape\n",
    "    result_key_points_list = []\n",
    "    for point in key_point_list:\n",
    "        histogram = np.zeros(shape=n_bins)\n",
    "        sigma_dist = np.abs(total_blurring_map - point.sigma)\n",
    "        closest_scale = np.argmin(sigma_dist) % (n_sample_per_octave)\n",
    "        current_octave = int(np.argmin(sigma_dist) // n_sample_per_octave)\n",
    "\n",
    "        safety_dist = 3 * l_ori * point.sigma\n",
    "        inter_pixel_distance_current_octave = inter_pixel_distance * 2 ** (current_octave - 1)\n",
    "        if not safety_dist < point.x < (plane_height - safety_dist) or not safety_dist < point.y < (plane_width - safety_dist):\n",
    "            continue\n",
    "        patch_corner_m_0 = int((point.x - safety_dist) / inter_pixel_distance_current_octave)\n",
    "        patch_corner_m_1 = int((point.x + safety_dist) / inter_pixel_distance_current_octave)\n",
    "        patch_corner_n_0 = int((point.y - safety_dist) / inter_pixel_distance_current_octave)\n",
    "        patch_corner_n_1 = int((point.y + safety_dist) / inter_pixel_distance_current_octave)\n",
    "\n",
    "        for m in range(patch_corner_m_0, patch_corner_m_1):\n",
    "            for n in range(patch_corner_n_0, patch_corner_n_1):\n",
    "                grad_m = gradient_m[current_octave, closest_scale][m, n]\n",
    "                grad_n = gradient_n[current_octave, closest_scale][m, n]\n",
    "\n",
    "                gradient_magnitude = sqrt(grad_m ** 2 + grad_n ** 2)\n",
    "                relative_m = m * inter_pixel_distance_current_octave - point.x\n",
    "                relative_n = n * inter_pixel_distance_current_octave - point.y\n",
    "                pt_orientation_share = exp(-(relative_m ** 2 + relative_n ** 2) / (2 * (l_ori * point.sigma) ** 2)) * gradient_magnitude\n",
    "                ori = atan2(grad_n, grad_m) % (2 * pi)\n",
    "                pt_orientation_bin = floor(n_bins / (2 * pi) * ori) % (n_bins)\n",
    "                histogram[pt_orientation_bin] += pt_orientation_share\n",
    "\n",
    "        smoothed_histogram = smoothHist(histogram)\n",
    "        histogram_max_value = smoothed_histogram.max()\n",
    "\n",
    "        refrence_angles = []\n",
    "        for k in range(n_bins):\n",
    "            h_p = smoothed_histogram[k - 1]\n",
    "            h_n = smoothed_histogram[(k + 1) % n_bins]\n",
    "            h_c = smoothed_histogram[k]\n",
    "            if h_p < h_c and h_c > h_n and h_c > t_secondary * histogram_max_value:\n",
    "                # fix\n",
    "                angle_at_bin_k = 2 * pi * (k + 1) / n_bins\n",
    "                key_ori = angle_at_bin_k + pi / n_bins * (h_p - h_n) / (h_p - 2 * h_c + h_n)\n",
    "                refrence_angles.append(key_ori)\n",
    "\n",
    "        for angle in refrence_angles:\n",
    "            finalized_key_point = copy.deepcopy(point)\n",
    "            finalized_key_point.orientation = angle\n",
    "            result_key_points_list.append(finalized_key_point)\n",
    "\n",
    "    return result_key_points_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EaxZmFceX8zR"
   },
   "source": [
    "### Computing descriptor for each key point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJ_Gs-H5X8zS",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def computeDescriptor(key_point_list, gradient_of_scale_space, inter_pixel_distance, l_desc, n_ori, n_hist, n_octave, n_sample_per_octave, sigma_min):\n",
    "    total_blurring_map = generateBlurringMatrix2(n_octave=n_octave, n_scale_per_octave=n_sample_per_octave, sigma_min=sigma_min, inter_pixel_distance=inter_pixel_distance)\n",
    "    total_blurring_map = total_blurring_map[:, 1:-2]\n",
    "    gradient_m = gradient_of_scale_space[0]\n",
    "    gradient_n = gradient_of_scale_space[1]\n",
    "    gradient_m = gradient_m[:, 1:-2]\n",
    "    gradient_n = gradient_n[:, 1:-2]\n",
    "#     counter = 0\n",
    "    # img_to_draw = gradient_of_scale_space[0][1, 0]\n",
    "    result_key_points_list = []\n",
    "    h, w = gradient_m[1, 0].shape\n",
    "    for point in key_point_list:\n",
    "        sigma_dist = np.abs(total_blurring_map - point.sigma)\n",
    "        closest_scale = np.argmin(sigma_dist) % n_sample_per_octave\n",
    "        current_octave = int(np.argmin(sigma_dist) // n_sample_per_octave)\n",
    "        inter_pixel_distance_in_current_octave = inter_pixel_distance * 2 ** (current_octave - 1)\n",
    "\n",
    "        safety_dis = ceil(sqrt(2) * l_desc * point.sigma * (n_hist + 1) / n_hist)\n",
    "        if not safety_dis < point.x < h - safety_dis or not safety_dis < point.y < w - safety_dis:\n",
    "            continue\n",
    "\n",
    "        feature_desc = np.zeros(shape=n_hist ** 2 * n_ori, dtype=np.float32)\n",
    "        patch_hist = np.zeros(shape=(n_hist, n_hist, n_ori))\n",
    "        r_outer_patch = sqrt(2) * l_desc * point.sigma * (n_hist + 1) / n_hist\n",
    "\n",
    "        outer_patch_corner_m0 = int((point.x - r_outer_patch) / inter_pixel_distance_in_current_octave)\n",
    "        outer_patch_corner_m1 = int((point.x + r_outer_patch) / inter_pixel_distance_in_current_octave)\n",
    "        outer_patch_corner_n0 = int((point.y - r_outer_patch) / inter_pixel_distance_in_current_octave)\n",
    "        outer_patch_corner_n1 = int((point.y + r_outer_patch) / inter_pixel_distance_in_current_octave)\n",
    "\n",
    "        inner_patch_width = 2 * l_desc * point.sigma * (n_hist + 1) / n_hist\n",
    "        for m in range(outer_patch_corner_m0, outer_patch_corner_m1):\n",
    "            for n in range(outer_patch_corner_n0, outer_patch_corner_n1):\n",
    "                x_dist = m * inter_pixel_distance_in_current_octave - point.x\n",
    "                y_dist = n * inter_pixel_distance_in_current_octave - point.y\n",
    "                x_patch = (x_dist * cos(point.orientation) + y_dist * sin(point.orientation)) / point.sigma\n",
    "                y_patch = (-x_dist * sin(point.orientation) + y_dist * cos(point.orientation)) / point.sigma\n",
    "                if max(abs(x_patch), abs(y_patch)) < l_desc * (n_hist + 1) / n_hist:\n",
    "\n",
    "                    grad_m = gradient_m[current_octave, closest_scale][m, n]\n",
    "                    grad_n = gradient_n[current_octave, closest_scale][m, n]\n",
    "                    gradient_magnitude = sqrt(grad_m ** 2 + grad_n ** 2)\n",
    "                    ori = (atan2(grad_n, grad_m) % (2 * pi) - point.orientation) % (2 * pi)\n",
    "                    # ori_contrib = exp(-(x_patch ** 2 + y_patch ** 2) / (2 * (l_desc * point.sigma) ** 2)) * gradient_magnitude\n",
    "                    ori_contrib = exp(-(x_patch ** 2 + y_patch ** 2) / (2 * l_desc ** 2)) * gradient_magnitude\n",
    "\n",
    "                    failed = True\n",
    "\n",
    "                    for i in range(n_hist):\n",
    "                        for j in range(n_hist):\n",
    "                            x_i = (i + 1 - (1 + n_hist) / 2) * 2 * l_desc / n_hist\n",
    "                            y_j = (j + 1 - (1 + n_hist) / 2) * 2 * l_desc / n_hist\n",
    "                            if max(abs(x_i - x_patch), abs(y_j - y_patch)) <= 2 * l_desc / n_hist:\n",
    "                                for k in range(n_ori):\n",
    "                                    ori_k = 2 * pi / n_ori * (k + 1)\n",
    "                                    angle_dis = abs(ori_k - ori)\n",
    "                                    if abs(ori_k - ori) < 2 * pi / n_ori:\n",
    "                                        patch_hist[i, j, k] += (1 - n_hist / (2 * l_desc) * abs(x_patch - x_i)) * (1 - n_hist / (2 * l_desc) * abs(y_patch - y_j)) * (1 - n_ori / (2 * pi) * abs(ori - ori_k)) * ori_contrib\n",
    "#                                         failed = False\n",
    "#                     if failed:\n",
    "#                         counter += 1\n",
    "\n",
    "        feature_desc = patch_hist.flatten()\n",
    "        l2_feature_desc = np.linalg.norm(feature_desc)\n",
    "\n",
    "        feature_desc = np.minimum(feature_desc, .2 * l2_feature_desc)\n",
    "        feature_desc = np.minimum(feature_desc * 512 / l2_feature_desc, 255)\n",
    "\n",
    "        point.descriptor = feature_desc\n",
    "        result_key_points_list.append(point)\n",
    "#         print(len(result_key_points_list))\n",
    "        # print(\"failed:\", counter)\n",
    "\n",
    "    return result_key_points_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24AaXu7ZX8zV"
   },
   "source": [
    "### Detecting Key point default configurations is applied as default arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNrRpPu9X8zV",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def sift(img_in, n_octave=5, n_sample_per_octave=3, sigma_min=.8, sigma_in=.5, c_dog=.015, r_edge=10, l_ori=1.5, l_desc=6, inter_pixel_dist=1):\n",
    "    figures = []\n",
    "    print(\"input image size:\")\n",
    "    print(img_in.shape)\n",
    "\n",
    "    print(\"Generating Scale Space ... \")\n",
    "    s_space = generateDigitalGaussianScaleSpace(img_in, n_octave=n_octave, n_sample_per_octave=n_sample_per_octave, sigma_min=sigma_min, inter_pixel_distance=inter_pixel_dist, sigma_in=sigma_in)\n",
    "    figures.append(showSpace(s_space))\n",
    "    \n",
    "    print(\"Calculating DoG space ...\")\n",
    "    dog = generateDoG(s_space)\n",
    "    figures.append(showSpace(dog, color_map='gist_heat'))\n",
    "\n",
    "    print(\"Detecting Extremums ...\")\n",
    "    candidate_points = detectExtremums(dog, c_dog, sigma_min=sigma_min, inter_pixel_distance=inter_pixel_dist)\n",
    "    print(len(candidate_points))\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, \"Extremums\"))\n",
    "\n",
    "    print(\"Discarding low contrast DOG points(Conservative Test) .... \")\n",
    "    candidate_points = discardLowContrastPointsConservative(candidate_points, dog, c_dog)\n",
    "    drawKeyPoints(img_in, candidate_points, \"low contrase extremums discarded (conservative)\")\n",
    "    print(len(candidate_points))\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, \"low contrase extremums discarded (conservative)\"))\n",
    "\n",
    "    print(\"Refining key points positions ... \")\n",
    "    candidate_points = refinePositions(candidate_points, dog, n_attempts=5, inter_pixel_distance=inter_pixel_dist, sigma_min=sigma_min)\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, title=\"refined key points\"))\n",
    "    print(len(candidate_points))\n",
    "    \n",
    "    # for performance we have merged this step with extremum detection part\n",
    "    print(\"Discarding low contrast points after position refinement\")\n",
    "    candidate_points = discardLowContrastPoints(candidate_points, contrast=c_dog)\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, title=\"final thresholding dog discarding low contrast points\"))\n",
    "    print(len(candidate_points))\n",
    "\n",
    "    print(\"Discarding edge points ...\")\n",
    "    candidate_points = discardEdgeResponse(candidate_points, dog, r_edge, n_octave, n_sample_per_octave, sigma_min, inter_pixel_dist)\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, title=\"edge response discarded\"))\n",
    "    print(len(candidate_points))\n",
    "\n",
    "    print(\"Computing Scale space gradient ... \")\n",
    "    gradient_of_scale_space = space_gradient(s_space)\n",
    "\n",
    "    print(\"Detecting Keypoints Orientation ... \")\n",
    "    candidate_points = computeKeyPointOrientation(candidate_points, gradient_of_scale_space, l_ori, n_bins=36, t_secondary=.8, sigma_min=sigma_min, n_octave=n_octave, n_sample_per_octave=n_sample_per_octave, inter_pixel_distance=inter_pixel_dist)\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, title=\"orientation computed\"))\n",
    "    print(len(candidate_points))\n",
    "\n",
    "    print(\"Computing keypoints descriptor ...\")\n",
    "    candidate_points = computeDescriptor(candidate_points, gradient_of_scale_space, inter_pixel_distance=inter_pixel_dist, l_desc=l_desc, n_ori=8, n_hist=4, n_octave=n_octave, n_sample_per_octave=n_sample_per_octave, sigma_min=sigma_min)\n",
    "    figures.append(drawKeyPoints(img_in, candidate_points, title=\"descriptors computed\"))\n",
    "    print(len(candidate_points))\n",
    "\n",
    "    print(\"The End ...\")\n",
    "    return candidate_points, figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Rkki10UPX8zZ",
    "outputId": "2d10d71f-f3f5-4f72-8b58-29a5c879bbde",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "img1=cv2.imread(\"./SIFT_Python/reeses_puffs.png\",0).astype(np.float64) / 255\n",
    "img2=cv2.imread(\"./SIFT_Python/many_cereals.jpg\",0).astype(np.float64) / 255\n",
    "fig,axis=plt.subplots(1,2,figsize=(24,20))\n",
    "axis[0].imshow(img1)\n",
    "axis[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1,fig1=sift(img1)\n",
    "kp2,fig2=sift(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kymcxaCzg-qC",
    "outputId": "dba3c0e1-97b9-4f13-fa56-834d5313a2b8",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[2])\n",
    "ax[1].imshow(fig2[2])\n",
    "ax[0].set(title=\"Detecting Extremums\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/extra_NES_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/extra_NES_im1.png\"))\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[3])\n",
    "ax[1].imshow(fig2[3])\n",
    "ax[0].set(title=\"Conservative Thresholding\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/extra_DoGSoftThresh_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/extra_DoGSoftThresh_im1.png\"))\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[4])\n",
    "ax[1].imshow(fig2[4])\n",
    "ax[0].set(title=\"Refining Positions\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/extra_ExtrInterp_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/extra_ExtrInterp_im1.png\"))\n",
    "\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[5])\n",
    "ax[1].imshow(fig2[5])\n",
    "ax[0].set(title=\"Final Thresholding DoG\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/extra_DoGThresh_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/extra_DoGThresh_im1.png\"))\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[6])\n",
    "ax[1].imshow(fig2[6])\n",
    "ax[0].set(title=\"Discarding Edge Responses\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/extra_OnEdgeResp_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/extra_OnEdgeResp_im1.png\"))\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[7])\n",
    "ax[1].imshow(fig2[7])\n",
    "ax[0].set(title=\"Detecting Orientation\")\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/keys_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/keys_im1.png\"))\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(fig1[8])\n",
    "ax[1].imshow(fig2[8])\n",
    "ax[0].set(title=\"Computing Descriptors\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QySftHghY-K",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "des1 = np.array([point.descriptor for point in kp1]).astype(np.float32)\n",
    "des2 = np.array([point.descriptor for point in kp2]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MIN_MATCH_COUNT = 10\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < .7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "\n",
    "if len(good) > 0:\n",
    "    # Estimate homography between template and scene\n",
    "    src_pts = [kp1[m.queryIdx] for m in good]\n",
    "    dst_pts = [kp2[m.trainIdx] for m in good]\n",
    "    img1_height, img1_width = img1.shape\n",
    "    img2_height, img2_width = img2.shape\n",
    "\n",
    "    newimg = np.zeros(shape=(max(img1_height, img2_height), img1_width + img2_width))\n",
    "    newimg[:img1_height, :img1_width] = drawKeyPoints(img1,src_pts)* 255\n",
    "    newimg[:img2_height, img1_width:] = drawKeyPoints(img2,dst_pts) * 255\n",
    "    matches=newimg.copy()\n",
    "    \n",
    "    for i in range(len(good)):\n",
    "        pt1 = (int(src_pts[i].pt()[1]), int(src_pts[i].pt()[0]))\n",
    "        pt2 = (int(dst_pts[i].pt()[1] + img1_width), int(dst_pts[i].pt()[0]))\n",
    "        print(pt1, pt2)\n",
    "        newimg = cv2.line(newimg, pt1, pt2, (0, 0, 0), 1)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good), MIN_MATCH_COUNT))\n",
    "\n",
    "\n",
    "print (\"good Matches found :\")\n",
    "print (len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(24,20)).add_subplot().imshow(matches)\n",
    "fig,ax=plt.subplots(1,2,figsize=(24,20))\n",
    "ax[0].imshow(cv2.imread(\"./SIFT_Python/matching_keys_im0.png\"))\n",
    "ax[1].imshow(cv2.imread(\"./SIFT_Python/matching_keys_im1.png\"))\n",
    "\n",
    "plt.figure(figsize=(24, 20)).add_subplot().imshow(newimg)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(24, 20)).add_subplot().imshow(cv2.imread(\"./SIFT_Python/OUTmatches.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SIFT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
